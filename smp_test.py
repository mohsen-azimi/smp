# -*- coding: utf-8 -*-
"""smp_kaggle_uav.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TsqyVDd6z5Ud7jlSfdAL6k1Lpf22Y_ku

# Import Libraries
"""


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
import json

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
import torchvision
import torch.nn.functional as F
from torch.autograd import Variable

from PIL import Image
import cv2
import albumentations as A

import time
import os
from tqdm import tqdm

import smp_models

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
"""# Preprocessing"""


DATA_DIR = '../dataset/crack_seg_dataset'



def create_df(DIR):
    data_frame = pd.DataFrame(columns=['image_name', 'mask_name', 'path'])
    # for each folder under the data directory
    for folder in os.listdir(DIR):

        if folder != 'concrete_vt' and folder != 'concrete_plus' and folder != 'concrete_surface':
            print(f"{len(os.listdir(os.path.join(DIR, folder)))} files are being loaded from {os.path.join(DIR, folder)}")
            # for each image in the folder

            for file in os.listdir(os.path.join(DIR, folder)):
                # if the image is a mask
                if file.endswith('.jpg'):
                    # get the image name
                    image_name = file
                    # get the mask name
                    # check if png  file exists for that image
                    mask_name = file.replace('.jpg', '.png')
                    # get the mask path
                    path = os.path.join(DATA_DIR, folder)

                    # check if bot jpg and png files exist
                    if os.path.isfile(os.path.join(path, image_name)) and os.path.isfile(os.path.join(path, mask_name)):
                        data_frame = pd.concat([data_frame, pd.DataFrame([[image_name, mask_name, path]], columns=['image_name', 'mask_name', 'path'])])
    return data_frame

df = create_df(DATA_DIR)
print('Total Images: ', len(df))


# split data
random_state = 42
X_trainval, X_test = train_test_split(df, test_size=0.10, random_state=random_state, shuffle=True)
X_train, X_val = train_test_split(X_trainval, test_size=0.10, random_state=random_state, shuffle=True)

print('Train Size   : ', len(X_train))
print('Val Size     : ', len(X_val))
print('Test Size    : ', len(X_test))

id = 60

img = cv2.imread(os.path.join(X_train.iloc[id]['path'], X_train.iloc[id]['image_name']))
mask = cv2.imread(os.path.join(X_train.iloc[id]['path'], X_train.iloc[id]['mask_name']), 0)
# change mask to 0 and 1
mask = np.where(mask > 0, 1, 0)

print('Image Size', img.shape)
print('Mask Size', mask.shape)

# plt.imshow(img)
# plt.show()
#
# plt.imshow(mask)
# plt.show()

# plt.imshow(img)
# plt.imshow(mask * 255, alpha=0.6)
# plt.show()

"""# Dataset"""


class DroneDataset(Dataset):

    def __init__(self, data_frame, mean, std, transform=None, patch=False):
        self.X = data_frame
        self.transform = transform
        self.patches = patch
        self.mean = mean
        self.std = std

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        img = cv2.imread(os.path.join(self.X.iloc[idx]['path'], self.X.iloc[idx]['image_name']))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(os.path.join(self.X.iloc[idx]['path'], self.X.iloc[idx]['mask_name']), 0)
        mask = np.where(mask > 0, 1, 0)
        # Mohsen { instead of this check, added a resize transform to the train and val transforms}
        h, w, c = img.shape
        # print("Before:", img.shape, mask.shape)
        output_stride = 32  # self.encoder.output_stride
        if h % output_stride != 0 or w % output_stride != 0:
            # print("OHHHHHHHHHHH")
            new_h = (h // output_stride + 1) * output_stride if h % output_stride != 0 else h
            new_w = (w // output_stride + 1) * output_stride if w % output_stride != 0 else w

            img = cv2.copyMakeBorder(img, 0, new_h - h, 0, new_w - w, borderType=cv2.BORDER_REFLECT)
            mask = cv2.copyMakeBorder(mask, 0, new_h - h, 0, new_w - w, borderType=cv2.BORDER_REFLECT)
        # print("After:", img.shape, mask.shape)
        # } Mohsen

        if self.transform is not None:
            aug = self.transform(image=img, mask=mask)
            img = Image.fromarray(aug['image'])
            mask = aug['mask']

        if self.transform is None:
            img = Image.fromarray(img)

        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])
        img = t(img)
        mask = torch.from_numpy(mask).long()

        if self.patches:
            img, mask = self.tiles(img, mask)

        return img, mask

    def tiles(self, img, mask):

        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)
        img_patches = img_patches.contiguous().view(3, -1, 512, 768)
        img_patches = img_patches.permute(1, 0, 2, 3)

        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)
        mask_patches = mask_patches.contiguous().view(-1, 512, 768)

        return img_patches, mask_patches


mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

resize_dims = (736, 1280) # must be % 32 = 0

t_test = A.Compose([A.Resize(resize_dims[0], resize_dims[1], interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),
                   A.GridDistortion(p=0.2)])

test_set = DroneDataset(X_test, mean, std, t_test, patch=False)

models = smp_models.return_models()


def mIoU(pred_mask, mask, smooth=1e-10, n_classes=23):
    with torch.no_grad():
        pred_mask = F.softmax(pred_mask, dim=1)
        pred_mask = torch.argmax(pred_mask, dim=1)
        pred_mask = pred_mask.contiguous().view(-1)
        mask = mask.contiguous().view(-1)

        iou_per_class = []
        for clas in range(0, n_classes):  # loop per pixel class
            true_class = pred_mask == clas
            true_label = mask == clas

            if true_label.long().sum().item() == 0:  # no exist label in this loop
                iou_per_class.append(np.nan)
            else:
                intersect = torch.logical_and(true_class, true_label).sum().float().item()
                union = torch.logical_or(true_class, true_label).sum().float().item()

                iou = (intersect + smooth) / (union + smooth)
                iou_per_class.append(iou)
        return np.nanmean(iou_per_class)





"""# Evaluation"""



from torchvision.transforms.functional import normalize

def predict_image_mask_miou(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    t = T.Compose([T.ToPILImage(), T.ToTensor()])
    image = t(image)
    image = normalize(image, mean, std)

    # model.to(device)
    # model.to(torch.device('cpu'))
    image = image.to(device)
    mask = mask.to(device)
    with torch.no_grad():
        image = image.unsqueeze(0)
        mask = mask.unsqueeze(0)

        output = model(image)
        score = mIoU(output, mask)
        masked = torch.argmax(output, dim=1)
        masked = masked.cpu().squeeze(0)
    return masked, score


def miou_score(model, test_set):
    score_iou = []
    for i in tqdm(range(len(test_set))):
        img, mask = test_set[i]
        pred_mask, score = predict_image_mask_miou(model, img, mask)
        score_iou.append(score)
    return score_iou


def predict_image_mask_pixel(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):
    model.eval()
    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])
    image = t(image)
    model.to(device);
    image = image.to(device)
    mask = mask.to(device)
    with torch.no_grad():
        image = image.unsqueeze(0)
        mask = mask.unsqueeze(0)

        output = model(image)
        acc = pixel_accuracy(output, mask)
        masked = torch.argmax(output, dim=1)
        masked = masked.cpu().squeeze(0)
    return masked, acc


def pixel_acc(model, test_set):
    accuracy = []
    for i in tqdm(range(len(test_set))):
        img, mask = test_set[i]
        pred_mask, acc = predict_image_mask_pixel(model, img, mask)
        accuracy.append(acc)
        # print("picel Accuracy: ", accuracy)
    return accuracy


# plot tool
def plot_img_mask_pred(image, mask, pred_mask, model_name, score):
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 5))

    image = np.transpose(image, (1, 2, 0))

    ax1.imshow(image)
    ax1.set_title('Picture')

    ax2.imshow(mask)
    ax2.set_title('Ground truth')
    ax2.set_axis_off()

    print(np.unique(pred_mask))
    ax3.imshow(pred_mask)
    ax3.set_title('{}_MobileNet | mIoU {:.3f}'.format(model_name, score))
    ax3.set_axis_off()

    plt.show()


image, mask = test_set[5]
masks_all = None
TRY_num = 0
import segmentation_models_pytorch as smp
device = torch.device("cpu")

n_classes = 2
en = 'mobilenet_v2'  # encoder_name : resnet34
ew = 'imagenet'  # encoder_weights
ed = 5  # encoder_depth
eos = 16  # encoder_output_stride
device = torch.device("cpu")

model = smp.Unet(encoder_name=en, encoder_depth=ed, encoder_weights=ew, decoder_use_batchnorm=True,
                 decoder_channels=(256, 128, 64, 32, 16), decoder_attention_type=None, in_channels=3,
                 classes=n_classes,
                 activation=None, aux_params=None)


# Load the trained model weights to the CPU
# Load the trained model weights to the CPU
checkpoint = torch.load('./results/Unet/Unet-_mIoU-0.768.pt', map_location=device)

# Access the state dict from the checkpoint object
state_dict = checkpoint['state_dict'].module

# Load the state dict to the model
model.load_state_dict(state_dict)

# Set the model to evaluation mode
model.eval()






pred_mask, score = predict_image_mask_miou(model, image, mask)
# print(image.shape, mask.shape, pred_mask.shape)
plot_img_mask_pred(image, mask, pred_mask, model.__class__.__name__, score)
if masks_all is None:
    masks_all = pred_mask
else:
    masks_all = masks_all | pred_mask
pred_masks_all = Image.fromarray((255 * masks_all).numpy().astype(np.uint8))
# pred_masks_all.save("z_masks_all_output.png")
# image.save("z_image_input.png")

gt = Image.fromarray((255 * mask).numpy().astype(np.uint8))
# gt.save("gt_mask.png")

segg = Image.fromarray((255 * pred_mask).numpy().astype(np.uint8))
# segg.save(f"seg_{model.__class__.__name__}.png")



# plot tool
fig, (ax1) = plt.subplots(1, 1, figsize=(10, 5))
ax1.imshow(masks_all)
ax1.set_title('all')

plt.show()



# Save all outputs from all models
mean_IoUs = []
mean_pixelAccs = []
'''
with open(f'./smp_cracks/iou_results.txt', 'w') as f:
    for _, model in models.items():
        print(model.__class__.__name__)
        model = torch.load(f'./smp_cracks/train_results/{model.__class__.__name__}_{TRY_num}.pt')

        # mean_IoUs.append(miou_score(model, test_set))
        # mean_pixelAccs.append(pixel_acc(model, test_set))

        for indx in range(test_set.__len__()):
            file_id = test_set.X[indx]
            image, mask = test_set[indx]
            pred_mask, score_miou = predict_image_mask_miou(model, image, mask)

            pred_pil = Image.fromarray((255 * pred_mask).numpy().astype(np.uint8))

            imagein = f"./smp_cracks/{model.__class__.__name__}/{file_id}.jpg"
            maskin = f"./smp_cracks/{model.__class__.__name__}/{file_id}_maskin.png"
            maskout = f"./smp_cracks/{model.__class__.__name__}/{file_id}_maskout.png"
            f.write(f"{model.__class__.__name__} {file_id} {score_miou:.3f}\n")  # to log the results

            image.save(imagein)
            mask.save(maskin)
            pred_pil.save(maskout)

i = 0
for _, model in models.items():
    print(model.__class__.__name__)
    mob_miou = mean_IoUs[i]
    mob_acc = mean_pixelAccs[i]
    print('Test Set mIoU', np.mean(mob_miou))
    print('Test Set Pixel Accuracy', np.mean(mob_acc))
    print("========================\n\n")
    i += 1

'''
