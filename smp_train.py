# -*- coding: utf-8 -*-
"""smp_kaggle_uav.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TsqyVDd6z5Ud7jlSfdAL6k1Lpf22Y_ku

# Import Libraries
"""

import numpy as np
import pandas as pd
# import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
import torchvision
import torch.nn.functional as F
from torch.autograd import Variable

from PIL import Image
import cv2
import albumentations as A

import time
import os
from tqdm import tqdm

# !pip install -q segmentation-models-pytorch
# !pip install -q torchsummary

from torchsummary import summary
import segmentation_models_pytorch as smp

import smp_models

import git_update as git
git.git_push()


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""# Preprocessing"""

# from google.colab import drive
# drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab_Temporary

# IMAGE_PATH = './smp_cracks/crack_dataset/images/'
# MASK_PATH = './smp_cracks/crack_dataset/annotations/'

DATA_DIR = '../dataset/crack_seg_dataset'



def create_df(DIR):
    data_frame = pd.DataFrame(columns=['image_name', 'mask_name', 'path'])
    # for each folder under the data directory
    for folder in os.listdir(DIR):

        if folder != 'concrete_vt':
            print(f"{len(os.listdir(os.path.join(DIR, folder)))} files are being loaded from {os.path.join(DIR, folder)}")
            # for each image in the folder

            for file in os.listdir(os.path.join(DIR, folder)):
                # if the image is a mask
                if file.endswith('.jpg'):
                    # get the image name
                    image_name = file
                    # get the mask name
                    # check if png  file exists for that image
                    mask_name = file.replace('.jpg', '.png')
                    # get the mask path
                    path = os.path.join(DATA_DIR, folder)

                    # check if bot jpg and png files exist
                    if os.path.isfile(os.path.join(path, image_name)) and os.path.isfile(os.path.join(path, mask_name)):
                        data_frame = pd.concat([data_frame, pd.DataFrame([[image_name, mask_name, path]], columns=['image_name', 'mask_name', 'path'])])
    return data_frame

df = create_df(DATA_DIR)
print('Total Images: ', len(df))


# split data
random_state = 42
X_trainval, X_test = train_test_split(df, test_size=0.10, random_state=random_state, shuffle=True)
X_train, X_val = train_test_split(X_trainval, test_size=0.10, random_state=random_state, shuffle=True)

print('Train Size   : ', len(X_train))
print('Val Size     : ', len(X_val))
print('Test Size    : ', len(X_test))

id = 60

img = cv2.imread(os.path.join(X_train.iloc[id]['path'], X_train.iloc[id]['image_name']))
mask = cv2.imread(os.path.join(X_train.iloc[id]['path'], X_train.iloc[id]['mask_name']), 0)
# change mask to 0 and 1
mask = np.where(mask > 0, 1, 0)

print('Image Size', img.shape)
print('Mask Size', mask.shape)

# plt.imshow(img)
# plt.show()
#
# plt.imshow(mask)
# plt.show()

# plt.imshow(img)
# plt.imshow(mask * 255, alpha=0.6)
# plt.show()

"""# Dataset"""


class DroneDataset(Dataset):

    def __init__(self, data_frame, mean, std, transform=None, patch=False):
        self.X = data_frame
        self.transform = transform
        self.patches = patch
        self.mean = mean
        self.std = std

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        img = cv2.imread(os.path.join(self.X.iloc[idx]['path'], self.X.iloc[idx]['image_name']))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mask = cv2.imread(os.path.join(self.X.iloc[idx]['path'], self.X.iloc[idx]['mask_name']), 0)
        mask = np.where(mask > 0, 1, 0)
        # Mohsen { instead of this check, added a resize transform to the train and val transforms}
        h, w, c = img.shape
        # print("Before:", img.shape, mask.shape)
        output_stride = 32  # self.encoder.output_stride
        if h % output_stride != 0 or w % output_stride != 0:
            # print("OHHHHHHHHHHH")
            new_h = (h // output_stride + 1) * output_stride if h % output_stride != 0 else h
            new_w = (w // output_stride + 1) * output_stride if w % output_stride != 0 else w

            img = cv2.copyMakeBorder(img, 0, new_h - h, 0, new_w - w, borderType=cv2.BORDER_REFLECT)
            mask = cv2.copyMakeBorder(mask, 0, new_h - h, 0, new_w - w, borderType=cv2.BORDER_REFLECT)
        # print("After:", img.shape, mask.shape)
        # } Mohsen

        if self.transform is not None:
            aug = self.transform(image=img, mask=mask)
            img = Image.fromarray(aug['image'])
            mask = aug['mask']

        if self.transform is None:
            img = Image.fromarray(img)

        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])
        img = t(img)
        mask = torch.from_numpy(mask).long()

        if self.patches:
            img, mask = self.tiles(img, mask)

        return img, mask

    def tiles(self, img, mask):

        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)
        img_patches = img_patches.contiguous().view(3, -1, 512, 768)
        img_patches = img_patches.permute(1, 0, 2, 3)

        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)
        mask_patches = mask_patches.contiguous().view(-1, 512, 768)

        return img_patches, mask_patches


mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]

# resize defaul = 704, 1056
resize_dims = (736, 1280) # must be % 32 = 0
t_train = A.Compose([A.Resize(resize_dims[0], resize_dims[1], interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(),
                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0, 0.5), (0, 0.5)),
                     A.GaussNoise()])

t_val = A.Compose([A.Resize(resize_dims[0], resize_dims[1], interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),
                   A.GridDistortion(p=0.2)])



# datasets
train_set = DroneDataset(X_train, mean, std, t_train, patch=False)
val_set = DroneDataset(X_val, mean, std, t_val, patch=False)
test_set = DroneDataset(X_test, mean, std, t_val, patch=False)

all_data = torch.utils.data.ConcatDataset([train_set, val_set, test_set])

print(len(train_set), '+', len(val_set), '+', len(test_set), '=', len(all_data))

# dataloader
batch_size = 4

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False, num_workers=4)
val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4)

models = smp_models.return_models()
# check if a folder is created for all the models in "./results"
for model_name in models.keys():
    if not os.path.exists(os.path.join("./results", model_name)):
        os.makedirs(os.path.join("./results", model_name))




"""# Training"""



def pixel_accuracy(output, mask):
    with torch.no_grad():
        output = torch.argmax(F.softmax(output, dim=1), dim=1)
        correct = torch.eq(output, mask).int()
        accuracy = float(correct.sum()) / float(correct.numel())
    return accuracy


def mIoU(pred_mask, mask, smooth=1e-10, n_classes=23):
    with torch.no_grad():
        pred_mask = F.softmax(pred_mask, dim=1)
        pred_mask = torch.argmax(pred_mask, dim=1)
        pred_mask = pred_mask.contiguous().view(-1)
        mask = mask.contiguous().view(-1)

        iou_per_class = []
        for clas in range(0, n_classes):  # loop per pixel class
            true_class = pred_mask == clas
            true_label = mask == clas

            if true_label.long().sum().item() == 0:  # no exist label in this loop
                iou_per_class.append(np.nan)
            else:
                intersect = torch.logical_and(true_class, true_label).sum().float().item()
                union = torch.logical_or(true_class, true_label).sum().float().item()

                iou = (intersect + smooth) / (union + smooth)
                iou_per_class.append(iou)
        return np.nanmean(iou_per_class)


def get_lr(optimizer):
    for param_group in optimizer.param_groups:
        return param_group['lr']


def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):
    torch.cuda.empty_cache()
    train_losses = []
    test_losses = []
    val_iou = []
    val_acc = []
    train_iou = []
    train_acc = []
    lrs = []
    min_loss = np.inf
    decrease = 1
    not_improve = 0

    model.to(device)
    fit_time = time.time()
    # create a txt file to save the progress of the training
    with open(os.path.join(f"./results/{model.__class__.__name__}/train_progress.txt"), "w") as f:
        f.write(f"Train Progress of {model.__class__.__name__} model \n")
    for e in range(epochs):


        since = time.time()
        running_loss = 0
        iou_score = 0
        accuracy = 0
        # training loop
        model.train()
        for i, data in enumerate(tqdm(train_loader)):
            # training phase
            # print(f"Epoch {e + 1}/{epochs} \t", end="")
            image_tiles, mask_tiles = data

            # if patch:
            #     bs, n_tiles, c, h, w = image_tiles.size()
            #
            #     image_tiles = image_tiles.view(-1, c, h, w)
            #     mask_tiles = mask_tiles.view(-1, h, w)

            image = image_tiles.to(device)
            mask = mask_tiles.to(device)
            # forward
            output = model(image)
            loss = criterion(output, mask)
            # evaluation metrics
            iou_score += mIoU(output, mask)
            accuracy += pixel_accuracy(output, mask)
            # backward
            loss.backward()
            optimizer.step()  # update weight
            optimizer.zero_grad()  # reset gradient

            # step the learning rate
            lrs.append(get_lr(optimizer))
            scheduler.step()

            running_loss += loss.item()

        else:
            model.eval()
            test_loss = 0
            test_accuracy = 0
            val_iou_score = 0
            # validation loop
            with torch.no_grad():
                for i, data in enumerate(tqdm(val_loader)):
                    # reshape to 9 patches from single image, delete batch size
                    image_tiles, mask_tiles = data
                    # print(f"training: {data[0].shape(), data[1].shape()}")

                    if patch:
                        bs, n_tiles, c, h, w = image_tiles.size()

                        image_tiles = image_tiles.view(-1, c, h, w)
                        mask_tiles = mask_tiles.view(-1, h, w)

                    image = image_tiles.to(device)
                    mask = mask_tiles.to(device)
                    output = model(image)
                    # evaluation metrics
                    val_iou_score += mIoU(output, mask)
                    test_accuracy += pixel_accuracy(output, mask)
                    # loss
                    loss = criterion(output, mask)
                    test_loss += loss.item()

            # calculatio mean for each batch
            train_losses.append(running_loss / len(train_loader))
            test_losses.append(test_loss / len(val_loader))

            if min_loss > (test_loss / len(val_loader)):
                print('Loss Decreasing.. {:.3f} >> {:.3f} '.format(min_loss, (test_loss / len(val_loader))))
                # save this txt to the train progress file
                with open(os.path.join(f"./results/{model.__class__.__name__}/train_progress.txt"), "a") as f:
                    f.write(f"Loss Decreasing.. {min_loss} >> {(test_loss / len(val_loader))} \n")

                min_loss = (test_loss / len(val_loader))
                decrease += 1
                if decrease % 5 == 0:
                    print('saving model...')
                    torch.save(model,
                               f'./results/{model.__class__.__name__}/{model.__class__.__name__}-{en}_mIoU-{val_iou_score / len(val_loader):.3f}.pt')

            if (test_loss / len(val_loader)) > min_loss:
                not_improve += 1
                min_loss = (test_loss / len(val_loader))
                print(f'Loss Not Decrease for {not_improve} time')
                # save this txt to the train progress file
                with open(os.path.join(f"./results/{model.__class__.__name__}/train_progress.txt"), "a") as f:
                    f.write(f"Loss Not Decrease for {not_improve} time \n")
                if not_improve == 10:
                    print('Loss not decrease for 10 times, Stop Training')
                    # save this txt to the train progress file
                    with open(os.path.join(f"./results/{model.__class__.__name__}/train_progress.txt"), "a") as f:
                        f.write(f"Loss not decrease for 10 times, Stop Training \n")
                    break

            # iou
            val_iou.append(val_iou_score / len(val_loader))
            train_iou.append(iou_score / len(train_loader))
            train_acc.append(accuracy / len(train_loader))
            val_acc.append(test_accuracy / len(val_loader))
            print("Epoch:{}/{}..".format(e + 1, epochs),
                  "Train Loss: {:.3f}..".format(running_loss / len(train_loader)),
                  "Val Loss: {:.3f}..".format(test_loss / len(val_loader)),
                  "Train mIoU:{:.3f}..".format(iou_score / len(train_loader)),
                  "Val mIoU: {:.3f}..".format(val_iou_score / len(val_loader)),
                  "Train Acc:{:.3f}..".format(accuracy / len(train_loader)),
                  "Val Acc:{:.3f}..".format(test_accuracy / len(val_loader)),
                  "Time: {:.2f}m".format((time.time() - since) / 60))

            # save this txt to the train progress file
            with open(os.path.join(f"./results/{model.__class__.__name__}/train_progress.txt"), "a") as f:
                f.write(f"Epoch:{e + 1}/{epochs}.. Train Loss: {running_loss / len(train_loader)}.. Val Loss: {test_loss / len(val_loader)}.. Train mIoU:{iou_score / len(train_loader)}.. Val mIoU: {val_iou_score / len(val_loader)}.. Train Acc:{accuracy / len(train_loader)}.. Val Acc:{test_accuracy / len(val_loader)}.. Time: {(time.time() - since) / 60}m \n")

        # save the model for each epoch to resume the training if it is interrupted
        torch.save(model.state_dict(), os.path.join(f"./results/{model.__class__.__name__}/model_epoch_{e+1}.pth"))
        print(f"Model saved for epoch {e+1}/ {epochs}")

    history = {'train_loss': train_losses, 'val_loss': test_losses,
               'train_miou': train_iou, 'val_miou': val_iou,
               'train_acc': train_acc, 'val_acc': val_acc,
               'lrs': lrs}
    print('Total time: {:.2f} m'.format((time.time() - fit_time) / 60))
    return history


print(models.keys())

histories = {}
import json

TRAIN = True
LOAD_pt = False
TRY_num = 0
if TRAIN:
    for _, model in models.items():
        print(model.__class__.__name__)
        if LOAD_pt:
            model = torch.load(f'./results/{model.__class__.__name__}/{model.__class__.__name__}_{TRY_num - 1}.pt')

        max_lr = 1e-3
        epoch = 20
        weight_decay = 1e-4

        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)
        sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch,
                                                    steps_per_epoch=len(train_loader))

        history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)

        torch.save(model, f'./results/{model.__class__.__name__}/{model.__class__.__name__}_{TRY_num}.pt')
        with open(f'./results/{model.__class__.__name__}/{model.__class__.__name__}_history_{TRY_num}.json', 'w') as f:
            f.write(json.dumps(history))
        del history

        # histories[model.__class__.__name__] = history
